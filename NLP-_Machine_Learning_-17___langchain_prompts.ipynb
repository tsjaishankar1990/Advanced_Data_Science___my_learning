{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2f8212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T08:19:49.294037Z",
     "start_time": "2023-04-08T08:19:47.533476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- Many of the styles here are inspired by: \n",
       "    https://towardsdatascience.com/10-practical-tips-you-need-to-know-to-personalize-jupyter-notebook-fbd202777e20 \n",
       "       \n",
       "    \n",
       "    On the author's local machine, these exist in the custom.css file. However, in order to keep uniform look and feel, \n",
       "    and at the request of participants, I have added it to this common import-file here.\n",
       "\n",
       "    -->\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Lora:400,700|Montserrat:300\" rel=\"stylesheet\">\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Crimson+Pro&family=Literata&display=swap\" rel=\"stylesheet\">\n",
       "<style>\n",
       "\n",
       "\n",
       "#ipython_notebook::before{\n",
       " content:\"NLP with Transformers\";\n",
       "        color: white;\n",
       "        font-weight: bold;\n",
       "        text-transform: uppercase;\n",
       "        font-family: 'Lora',serif;\n",
       "        font-size:16pt;\n",
       "        margin-bottom:15px;\n",
       "        margin-top:15px;\n",
       "           \n",
       "}\n",
       "body > #header {\n",
       "    #background: #D15555;\n",
       "    background: linear-gradient(to bottom, indianred 0%, #fff 100%);\n",
       "    opacity: 0.8;\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       ".navbar-default .navbar-nav > li > a, #kernel_indicator {\n",
       "    color: white;\n",
       "    transition: all 0.25s;\n",
       "    font-size:10pt;\n",
       "    font-family: sans-serif;\n",
       "    font-weight:normal;\n",
       "}\n",
       ".navbar-default {\n",
       "    padding-left:100px;\n",
       "    background: none;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       "\n",
       "body > menubar-container {\n",
       "    background-color: wheat;\n",
       "}\n",
       "#ipython_notebook img{                                                                                        \n",
       "    display:block; \n",
       "    \n",
       "    background: url(\"https://www.supportvectors.com/wp-content/uploads/2016/03/logo-poster-smaller.png\") no-repeat;\n",
       "    background-size: contain;\n",
       "   \n",
       "    padding-left: 600px;\n",
       "    padding-right: 100px;\n",
       "    \n",
       "    -moz-box-sizing: border-box;\n",
       "    box-sizing: border-box;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "body {\n",
       " #font-family:  'Literata', serif;\n",
       "    font-family:'Lora', san-serif;\n",
       "    text-align: justify;\n",
       "    font-weight: 400;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "\n",
       "iframe{\n",
       "    width:100%;\n",
       "    min-height:600px;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "# font-family: 'Montserrat', sans-serif;\n",
       " font-family:'Lora', serif;\n",
       " font-weight: 200;\n",
       " text-transform: uppercase;\n",
       " color: #EC7063 ;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    color: #000080;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       "#notebook_name {\n",
       "    font-weight: 600;\n",
       "    font-size:20pt;\n",
       "    text-variant:uppercase;\n",
       "    color: wheat; \n",
       "    margin-right:20px;\n",
       "    margin-left:-500px;\n",
       "}\n",
       "#notebook_name:hover {\n",
       "background-color: salmon;\n",
       "}\n",
       "\n",
       "\n",
       ".dataframe { /* dataframe atau table */\n",
       "    background: white;\n",
       "    box-shadow: 0px 1px 2px #bbb;\n",
       "}\n",
       ".dataframe thead th, .dataframe tbody td {\n",
       "    text-align: center;\n",
       "    padding: 1em;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       ".output {\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    transition: all 0.25s;\n",
       "    border: none;\n",
       "    position: relative;\n",
       "    top: 0;\n",
       "}\n",
       "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
       "    border: none;\n",
       "    background: transparent;\n",
       "    box-shadow: 0 6px 18px #aaa;\n",
       "    z-index: 10;\n",
       "    top: -10px;\n",
       "}\n",
       ".CodeMirror pre, .CodeMirror-dialog, .CodeMirror-dialog .CodeMirror-search-field, .terminal-app .terminal {\n",
       "    font-family: 'Hack' , serif; \n",
       "    font-weight: 500;\n",
       "    font-size: 14pt;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "</style>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "<center><img src=\"https://d4x5p7s4.rocketcdn.me/wp-content/uploads/2016/03/logo-poster-smaller.png\"/> </center>\n",
       "<div style=\"color:#aaa;font-size:8pt\">\n",
       "<hr/>\n",
       "&copy; SupportVectors. All rights reserved. <blockquote>This notebook is the intellectual property of SupportVectors, and part of its training material. \n",
       "Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.\n",
       "\n",
       "<b> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</b>\n",
       " </blockquote>\n",
       " <hr/>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc25b9ff",
   "metadata": {},
   "source": [
    "# LangChain Prompts\n",
    "\n",
    "Good prompts have an overwhelming influence on the quality of the inferences from a large language model. Indeed, over the last few months, there is an increasing realization that the LLMs could potentially start to take over tasks traditionally accomplished through programming -- assuming we can give it well thought out prompts.\n",
    "\n",
    "<div class=\"alert-box alert-warning\" style=\"padding-top:30px\">\n",
    "   \n",
    "<b >Caveat Emptor</b>\n",
    "\n",
    "> A word of caution is necessary: programming is inherently deterministic, and comprises a clear set of instructions, that yield  -- within certain tolerances -- repeatable results.  </p> On the other hand, large language models are probabilistic machines, and depending on such hyper-parameters as the `temperature`, tend to yield different results on eahc invocation. Here, the value of `temperature` controls the output variations, with `temperature=0` producing close to repeatable results (one reason that this setting is often the default in many situations). On the other hand, higher value, say `temperature=0.9` will tend to produce different results each time.\n",
    ">\n",
    "> From our last week's session (our exploration of softmax-temperature), we recall that the temperature is a hyperparameter of the softmax classifier. In other words, when determining the probability of the next word $x_i$ from a vocabulary, the large language models use $$\\mathbf{softmax}(x_i/T) = \\frac{e^{x_i/T}}{\\sum_j e^{x_j/T}}$$ Therefore, the higher the temperature, the more the probability distribution is flattened, and thus a generative model is more likely to sample and pick not necessarily the most likely word, but the next ones in probability. In effect, this leads to a higher variation in the generated text.\n",
    "<p>\n",
    "</div>\n",
    "\n",
    "\n",
    "<hr/>\n",
    "\n",
    "A `langchain.PromptTemplate` contains two components:\n",
    "\n",
    "* a template text, with zero or more input-variables embedded in it\n",
    "* a list of these input variables\n",
    "\n",
    "Let us now explore a few examples of prompts to develop fluency with them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91275b98",
   "metadata": {},
   "source": [
    "### Imports needed for this lab\n",
    "\n",
    "Let us now import all the components we will need for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3785d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from IPython.display import Markdown, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc50763f",
   "metadata": {},
   "source": [
    "Consider a prompt that we may want to give a large language model:\n",
    "\n",
    "<div class=\"alert-box alert-info\" style=\"padding-top:30px\">\n",
    "    \n",
    "> Imagine that there is a story about cats. They like to drink milk and prawl in the neighborhood. Write a short story where some cats show these behaviors.\n",
    ">\n",
    "> Give the story a catchy, humorous title. Write it in the format:\n",
    ">        \n",
    ">        <h3> [Title] </h3>\n",
    ">        \n",
    ">        [Body of the story]\n",
    "    \n",
    "</div>\n",
    "As we learned earlier, we can easily do this with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c47de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "        Imagine that there is a story about cats. \n",
    "        They like to drink milk and prawl in the neighborhood. \n",
    "        Write a short story where some cats show these behaviors.\n",
    "        \n",
    "        Give the story a catchy, humorous title. Write it in the format:\n",
    "        \n",
    "        <h3> [Title] </h3>\n",
    "        \n",
    "        [Body of the story]\n",
    "        \"\"\"\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "story = llm(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51e20120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<blockquote>\n",
       "        <h3>Milky Mischief at Midnight</h3>\n",
       "\n",
       "It was a dark and stormy night when the cats of Mouseville crept out of their homes and into the streets. They wanted nothing more than to get their fill of the sweet, creamy milk they had been dreaming of all day. \n",
       "\n",
       "Patches, an old tabby, led the way, tiptoeing between the streetlights, searching for the perfect spot. Suddenly, the light of a nearby porch illuminated a carton of milk on the doorstep.\n",
       "\n",
       "The cats wasted no time devouring the contents of their find, lapping it up with a furry lip and purring with pleasure. Each lick seemed to bring them more joy than the last.\n",
       "\n",
       "But the cats weren't done yet. After they had their fill of milk, they scattered throughout the neighborhood, exploring every nook and cranny they could get their little paws on. They peered through windows, under decks, and behind trees. Nothing was beyond their curiosity. \n",
       "\n",
       "Just as fast as they had come, the cats of Mouseville vanished into the night, leaving behind only a few droplets of milk and the echoes of their cheery purrs.</blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown('<blockquote>' + story + '</blockquote>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fcdcac",
   "metadata": {},
   "source": [
    "#### Generate variations\n",
    "\n",
    "Since we set the temperature to `temperature=0.9`, we should expect a different story to emerge the next time we call invoke the model with the same input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c93db667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<blockquote>\n",
       "        <h3>Milk, Mews, and Prowling: Cats in the 'Hood</h3>\n",
       "\n",
       "In the quiet neighborhood of Sandberry Drive, cats can often be seen lounging around in the sun and exploring the area. They make a stop each night at Mrs. Dabbs' house to get a refreshing drink of milk, and then immediately return to their prowling.\n",
       "\n",
       "One particular evening, a group of cats led by the oldest of the bunch set out on their nightly adventure. They all leaped and tumbled their way around the streets and backyards, reveling in the delight of their newfound freedom. Every so often, they'd pause to let out a collective meow, as if to announce their presence to the neighborhood.\n",
       "\n",
       "At Mrs. Dabbs' house, the cats eagerly took their turn to each get a sip of the creamy milk. Fueled by the sustenance, they moved on, sniffing the ground along the way, and chasing their tail as they went.\n",
       "\n",
       "Before long, the cats reached the edge of a nearby park. Here, they broke off into small groups, taking advantage of every cranny and crevice they could find. The night was filled</blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "story = llm(prompt)\n",
    "display(Markdown('<blockquote>' + story + '</blockquote>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce499a3",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* Note how different the two stories about the cats are. This points to the non-determinism of the results.\n",
    "\n",
    "* We could have set the temperature to `temperature=0`, and seen results that were a bit more similar, yet not identical. We do that below to verify.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1083c809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Story of cats: Version 1 </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<blockquote>\n",
       "        <h3>The Cat's Meow-athon</h3>\n",
       "\n",
       "It was a warm, summer day in the neighborhood, and the cats were up to their usual antics. All the cats in the area had gathered in the yard of the old Victorian house, where they frolicked and played until their bellies were full and their fur was a mess. \n",
       "\n",
       "One particularly daring cat, named Morty, decided to lead the other cats on an adventure, and one by one they gathered around him and followed him to the nearby grocery store. Peeking through the window, they saw the glorious sight of a milk delivery truck, unloading gallons and gallons of milk into the dairy section. \n",
       "\n",
       "The cats all cheered in delight, and Morty wasted no time in making his way into the store. As he stumbled upon the milk delivery, a crowd of cats gathered around him, their eyes sparkling with delight. Morty quickly filled the front of his shirt with gallons of milk, before heading out the door and outrunning the store manager. \n",
       "\n",
       "After they had their fill of milk, the cats then made their way to the park, where they spent the rest of the day happily prawling around and exploring the area. The cats were exhausted by</blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4> Story of cats: Version 2 </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<blockquote>\n",
       "        <h3>The Milk Drinking, Prowling Cats of the Neighborhood</h3>\n",
       "\n",
       "One day, a group of cats from the neighborhood decided to go out and explore. They were particularly interested in the local grocery store, where they knew milk could be found. \n",
       "\n",
       "The cats were careful as they made their way around, keeping their eyes and ears peeled for any signs of danger. When they finally made it to the store, they were delighted to find an array of delicious dairy products. \n",
       "\n",
       "One adventurous tabby decided to check out the store's dairy section, while the rest of the cats stayed hidden in the shadows. The tabby snuck around the corner and, before anyone knew it, had lapped up a full carton of milk. After they finished, the cats made their way out of the store as quickly as they had come. \n",
       "\n",
       "The cats, now satisfied, spent the rest of the day prowling the neighborhood. They found sun-drenched spots to relax, interesting places to explore, and delicious scraps of food. \n",
       "\n",
       "The cats were content with their day of exploration, and had a great story to tell when they got back home. They were forever known as the milk drinking,</blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_llm = OpenAI(temperature=0.0)\n",
    "\n",
    "# The first version\n",
    "display (HTML('<h4>Story of cats: Version 1 </h4>'))\n",
    "story = llm(prompt)\n",
    "display(Markdown('<blockquote>' + story + '</blockquote>'))\n",
    "\n",
    "# The second version\n",
    "display (HTML('<h4> Story of cats: Version 2 </h4>'))\n",
    "story = llm(prompt)\n",
    "display(Markdown('<blockquote>' + story + '</blockquote>'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0982422d",
   "metadata": {},
   "source": [
    "## From prompts to templates\n",
    "\n",
    "Instead of cats, what if we wanted a story about dogs, or about squirrels? A moment of reflection would show that we could have done it with minor variations to our prompt:\n",
    "\n",
    "**For dogs **\n",
    "\n",
    "<div class=\"alert-box alert-info\" style=\"padding-top:30px\">   \n",
    "\n",
    "> Imagine that there is a story about dogs. They like to chew on toys, play fetch and run around the park. Write a short story where some dogs show these behaviors.\n",
    ">\n",
    "> Give the story a catchy, humorous title. Write it in the format:\n",
    ">        \n",
    ">        <h3> [Title] </h3>\n",
    ">        \n",
    ">        [Body of the story]\n",
    "    \n",
    "</div>\n",
    "\n",
    "**For squirrels **\n",
    "\n",
    "<div class=\"alert-box alert-info\" style=\"padding-top:30px\">   \n",
    "\n",
    "> Imagine that there is a story about squirrels. They like to eat nuts and fruits, climb up and down trees and run around the glassy meadows. Write a short story where some squirrels show these behaviors.\n",
    ">\n",
    "> Give the story a catchy, humorous title. Write it in the format:\n",
    ">        \n",
    ">        <h3> [Title] </h3>\n",
    ">        \n",
    ">        [Body of the story]\n",
    "    \n",
    "</div>\n",
    "\n",
    "### Capture commonality in templates\n",
    "\n",
    "Do we see the close similarity between the prompts? Perhaps we would like a lot of stories about animals, and we need to simply give a few descriptive behaviors so the large language models can weave a story around them.\n",
    "\n",
    "Let us make the above prompts into a template, with two inputs:\n",
    "\n",
    "* name of the animal\n",
    "* some characteristic behaviors of the animal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea33ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "\n",
    "        Imagine that there is a story about {animal}. \n",
    "        They like to {behaviors}. \n",
    "        Write a short story where some {animal} show these behaviors.\n",
    "        \n",
    "        Give the story a catchy, humorous title. Write it in the format:\n",
    "        \n",
    "        <h4> [Title] </h4>\n",
    "        \n",
    "        [Body of the story]\n",
    "\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f163273a",
   "metadata": {},
   "source": [
    "Then we can generate our prompt for a story about dogs with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "381ee515",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "            input_variables = ['animal', 'behaviors'],\n",
    "            template        = template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a4fe60",
   "metadata": {},
   "source": [
    "Then, for a story about dogs, we can generate the prompt text as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9789a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "        Imagine that there is a story about dogs. \n",
      "        They like to chew on toys, play fetch and run around the park. \n",
      "        Write a short story where some dogs show these behaviors.\n",
      "        \n",
      "        Give the story a catchy, humorous title. Write it in the format:\n",
      "        \n",
      "        <h4> [Title] </h4>\n",
      "        \n",
      "        [Body of the story]\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "dogs = 'dogs'\n",
    "dog_behaviors = 'chew on toys, play fetch and run around the park'\n",
    "\n",
    "for_dogs = prompt.format(animal = dogs, behaviors = dog_behaviors)\n",
    "print(for_dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3027731",
   "metadata": {},
   "source": [
    "Likewise, for squirrels, we could get the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "742b1f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "        Imagine that there is a story about squirrels. \n",
      "        They like to eat nuts and fruits, \n",
      "        climb up and down trees and run around the glassy meadows. \n",
      "        Write a short story where some squirrels show these behaviors.\n",
      "        \n",
      "        Give the story a catchy, humorous title. Write it in the format:\n",
      "        \n",
      "        <h4> [Title] </h4>\n",
      "        \n",
      "        [Body of the story]\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "squirrels = 'squirrels'\n",
    "squirrel_behaviors = \"\"\"eat nuts and fruits, \n",
    "        climb up and down trees and run around the glassy meadows\"\"\"\n",
    "\n",
    "for_squirrels = prompt.format(animal = squirrels, behaviors = squirrel_behaviors)\n",
    "print (for_squirrels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b5bbb",
   "metadata": {},
   "source": [
    "#### A simple LangChain \n",
    "\n",
    "Let us concatenate the `promptTemplate` and the `llm` into a single chain, so we can invoke it with needing to invoke each component, and feeding its output to the next component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b7db5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f29b947",
   "metadata": {},
   "source": [
    "And now we can invoke it to, say, get a story about dogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f89321d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<blockquote>\n",
       "        <h4>A Bark in the Park</h4>\n",
       "\n",
       "There were four dogs, all eager to get to the park. When they arrived, they couldn't contain their excitement, each looking for something different. \n",
       "\n",
       "The first dog, a golden retriever, found a bright red ball and grabbed it in its mouth. It ran around the park, showing off the toy to its friends and eagerly awaiting someone to play fetch.\n",
       "\n",
       "The second dog, a shih tzu, spotted a bone and scurried over to it. Before anyone had a chance to take it away, it had chewed it into little pieces.\n",
       "\n",
       "The third dog, a Labrador, just wanted to run around the field. It sprinted back and forth, wagging its tail and happily barking.\n",
       "\n",
       "Finally, the fourth dog, a beagle, was content simply to wander around and sniff all the different smells.\n",
       "\n",
       "The four dogs had all enjoyed the park in their own way, and everyone was exhausted by the time they left.</blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "story = chain.run (animal=dogs, behaviors=dog_behaviors)\n",
    "display(Markdown('<blockquote>' + story + '</blockquote>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dec13ec",
   "metadata": {},
   "source": [
    "Likewise, a story about squirrels with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e15b8477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<blockquote>\n",
       "        <h4> Nuts and Fruits R Us </h4>\n",
       "\n",
       "The sun rose over the meadows in the morning, and a small group of squirrels were already bouncing across the grass. They raced around, chasing each other and playing hide and seek. Their excitement was contagious, and soon, even the birds and butterflies joined in the fun.\n",
       "\n",
       "The squirrels loved to explore and search for food. They scurried up the trees and through the branches, searching for nuts and fruits. As soon as they found something to eat, they quickly devoured it, leaving nothing behind.\n",
       "\n",
       "When their bellies were full, the squirrels took a break and decided to sunbathe on some of the trees. They rolled around the branches, their tiny little tails wiggling, and their laughter filling the air.\n",
       "\n",
       "The squirrels spent the day enjoying the fresh air and sunshine, and when night began to fall, they returned back to their homes in the trees. They scampered up the trunks and curled up in their nests, dreaming of the next fun-filled day to come.</blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "story = chain.run (animal=squirrels, behaviors=squirrel_behaviors)\n",
    "display(Markdown('<blockquote>' + story + '</blockquote>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a57e7",
   "metadata": {},
   "source": [
    "**Note**\n",
    "While a `LLMChain` will take a prompt-template as an argument, it is not necessary to provide a user input. For example, the following prompt template does not take any user input, and still forms a part of the chain, that we can invoke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68b519cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A witty quote on everyday life in contemporary times.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<blockquote>\n",
       "\n",
       "\"Life in the 21st century is like a roller coaster ride. You never know when you're going to drop, but you sure have fun when you do!\"</blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_prompt = PromptTemplate(\n",
    "    template=\"A witty quote on everyday life in contemporary times.\",\n",
    "    input_variables=[] # we cannot omit this argument, even if empty\n",
    ")\n",
    "print (simple_prompt.format())\n",
    "\n",
    "quote = llm(simple_prompt.format())\n",
    "display(Markdown('<blockquote>' + quote + '</blockquote>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd7a8d",
   "metadata": {},
   "source": [
    "#### Chain with a simple prompt\n",
    "\n",
    "We can run the chain with a simple prompt that needs no user input as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "859ee2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Life is like a roller coaster. Sometimes you get the thrills, sometimes you get the spills.\"\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=simple_prompt)\n",
    "witty_quote = chain.run (input=\"\")\n",
    "print(witty_quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be9b0f2",
   "metadata": {},
   "source": [
    "## Few shot examples\n",
    "\n",
    "It is often the case that we want to give the large language models a few exemplars, so that it can infer the relationships. Let us illustrate it with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8191ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Animal: {animal}\n",
    "Likes to: {likes_to}\n",
    "\"\"\"\n",
    "\n",
    "examples = [\n",
    "    {'animal': 'dog', 'likes_to': 'play fetch!'},\n",
    "    {'animal': 'cat', 'likes_to': 'prawl around the neighborhood'},\n",
    "    {'animal': 'squirrel', 'likes_to': 'eat nuts and climb trees'}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f7ee6b",
   "metadata": {},
   "source": [
    "Let us now create an example prompt from this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edb66b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables=['animal', 'likes_to'],\n",
    "    template = template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfb2ac8",
   "metadata": {},
   "source": [
    "Now, let's create the `FewShotPromptTemplate` with these two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b344772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt       = FewShotPromptTemplate(\n",
    "    examples          = examples,\n",
    "    example_prompt    = example_prompt,\n",
    "    prefix            = 'Describe the behavior of every animal input',\n",
    "    suffix            = 'Animal: {input}\\nLikes to:',\n",
    "    input_variables   = ['input'],\n",
    "    example_separator = '\\n\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf5229d",
   "metadata": {},
   "source": [
    "We can generate the prompt text from the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a31517a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe the behavior of every animal input\n",
      "\n",
      "\n",
      "Animal: dog\n",
      "Likes to: play fetch!\n",
      "\n",
      "\n",
      "\n",
      "Animal: cat\n",
      "Likes to: prawl around the neighborhood\n",
      "\n",
      "\n",
      "\n",
      "Animal: squirrel\n",
      "Likes to: eat nuts and climb trees\n",
      "\n",
      "\n",
      "Animal: horse\n",
      "Likes to:\n"
     ]
    }
   ],
   "source": [
    "text = few_shot_prompt.format(input='horse')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11a41062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' eat hay and run around in fields'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n",
    "chain.run('horse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112dd1f1",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "We have learned so far that a `prompt` in `langchain` is the input that goes into a large language model. As we will learn later, there are prompts for other things too, such as chat models, and so forth.\n",
    "\n",
    "In general, a `prompt` is not necessarily a pre-determined string, but can comprise:\n",
    "\n",
    "* a template (`PromptTemplate`), with  user input variables embedded\n",
    "* user inputs for each these variables\n",
    "* and also some examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4d89ad",
   "metadata": {},
   "source": [
    "## Partial Prompt Template\n",
    "\n",
    "Sometimes, we can construct a simpler prompt template by taking one that needs multiple user inputs, but hardwiring some (but not all) of these. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98eb60e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Name three historically significant events in England around the year 1800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "    Name three historically significant events in {country} around the year {year}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate (\n",
    "            input_variables = ['country', 'year'],\n",
    "            template        = template,\n",
    ")\n",
    "\n",
    "print(prompt.format(country='England', year='1800'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8731397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. The Acts of Union of England and Scotland in 1707 creating the united Kingdom of Great Britain\n",
      "2. The Industrial Revolution beginning in the late 1700â€™s\n",
      "3. The Battle of Trafalgar in October 1805\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "history = chain.run(country='England', year='1800')\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56fdc34",
   "metadata": {},
   "source": [
    "Let us now suppose that we are particularly interested in the French history.\n",
    "Then, we can create a simpler, partial prompt out of the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41b4cb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Name three historically significant events in France around the year 1789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "partial_prompt = prompt.partial(country='France')\n",
    "print(partial_prompt.format(year='1789'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f927b",
   "metadata": {},
   "source": [
    "And we can feed it into a language chain as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c72bd897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. The Storming of the Bastille (July 14, 1789)\n",
      "2. Declaration of the Rights of Man and of the Citizen (August 26, 1789)\n",
      "3. National Assembly Adopts New Constitution (September 3, 1791)\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(\n",
    "            llm     = llm,\n",
    "            prompt  = partial_prompt\n",
    ")\n",
    "\n",
    "events = chain.run(year='1789')\n",
    "print(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972be26b",
   "metadata": {},
   "source": [
    "## What we have learned?\n",
    "\n",
    "In this lab, we learned about:\n",
    "\n",
    "* what is a `langchain.PromptTemplate`, and what purpose it serves\n",
    "* many illustrations of constructing the prompt templates\n",
    "* using prompt templates with few shot examples\n",
    "* judicious choice of prompt template\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
